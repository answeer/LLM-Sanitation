{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1776f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Guard and Validator\n",
    "from guardrails.hub import ToxicLanguage\n",
    "from guardrails import Guard\n",
    "\n",
    "# Use the Guard with the validator\n",
    "guard = Guard().use(\n",
    "    ToxicLanguage, threshold=0.5, validation_method=\"sentence\", on_fail=\"fix\"\n",
    ")\n",
    "\n",
    "# # Test passing response\n",
    "# guard.validate(\"Love how you think and attack the problem. Great job!\")\n",
    "\n",
    "# try:\n",
    "#     # Test failing response\n",
    "#     guard.validate(\n",
    "#         \"Please look carefully. You are a stupid idiot who can't do anything right.\"\n",
    "#     )\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "\n",
    "text = \"Please look carefully. You are a stupid idiot who can't do anything right.\"\n",
    "\n",
    "raw_llm_output,validated_output, _, validation_passed, *rest= guard.parse(\n",
    "    llm_output=text,\n",
    "    metadata={},\n",
    ")\n",
    "\n",
    "print(\"raw_llm_output: \",raw_llm_output)\n",
    "print(\"validated_output: \",validated_output)\n",
    "print(\"validation_passed: \",validation_passed)\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
